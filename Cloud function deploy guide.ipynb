{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mh8bbrH0OsgU"
   },
   "source": [
    "# Individual config of trigger and output bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ti2zy3Tiko0r"
   },
   "outputs": [],
   "source": [
    "#You can create the buckets manually or with the following code.\n",
    "#In case you create it manually or you already have created the buckets, CHANGE the following variables names to the existing bucket ids.\n",
    "import uuid\n",
    "import os\n",
    "trigger_Bucket= \"trigger-\"+str(uuid.uuid4())   # create a global unique ID for your trigger bucket\n",
    "Output_Bucket= \"output-\"+str(uuid.uuid4())     # create a global unique ID for your output bucket\n",
    "PROJECT = \"cloudfunction-268018\" # REPLACE WITH YOUR PROJECT ID\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKOkuPeYkI3P"
   },
   "outputs": [],
   "source": [
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['trigger_Bucket'] = trigger_Bucket\n",
    "os.environ['Output_Bucket'] = Output_Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owMgKos0kI34",
    "outputId": "2ca88414-5d9c-4e72-d8bd-e7073119af6e"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project ${PROJECT}\n",
    "gcloud config set compute/region ${REGION}\n",
    "gsutil mb -l ${REGION} gs://${trigger_Bucket}\n",
    "gsutil mb -l ${REGION} gs://${Output_Bucket}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUCKET = \"cloudfunction-268018qwiklabs-gcp-02-19352bf770e7\" # REPLACE WITH YOUR BUCKET NAME\n",
    "#os.environ['BUCKET'] = BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#gsutil mb -l ${REGION} gs://${BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_oJzivKOgST"
   },
   "source": [
    "# Create dependencies file (requirements.txt) and execution file (main.py) for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5_EFV5QSh-2G",
    "outputId": "57ed8d37-f0d3-4177-b6cf-937fd8535e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pydub\n",
    "google-cloud-translate\n",
    "google-cloud-speech\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyrtAIhTkOKs"
   },
   "source": [
    "IMPORTNAT NOTE: Change OUTPUT_BUCKET to your created Output bucket. Following line gives you the ID of the output_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANH1DmNLPsr-",
    "outputId": "ccaf0222-8bc8-4049-8d03-3800591ff74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-39f8058a-242b-44ff-b2b3-b86aa36643fc\n"
     ]
    }
   ],
   "source": [
    "print(Output_Bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nORNwEqwh-7S",
    "outputId": "aa47df8e-8255-4409-83da-87afc62a55d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "OUTPUT_BUCKET = \"output-39f8058a-242b-44ff-b2b3-b86aa36643fc\" ##CHANGE: Insert your output-bucket id\n",
    "TARGET_LANGUAGE = \"de\" # Language code for the target language of the translation. In this case german\n",
    "FLAG_TRANSLATE=True # set false to not create an additional translation of the subtitles\n",
    "\n",
    "import datetime\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "from google.cloud import storage\n",
    "from google.cloud import translate_v2 as translate\n",
    "from google.cloud import storage\n",
    "import tempfile\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import sys\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "def get_file_path(filename):\n",
    "  \"\"\"\n",
    "  returns secure cloud functions node file destination path.\n",
    "  Should be usually tmp/[audiofile]. tmp folder is only accessible folder in CFunctions node to write and read. \n",
    "  \"\"\"\n",
    "  file_name = secure_filename(filename)\n",
    "  return os.path.join(tempfile.gettempdir(), file_name)\n",
    "\n",
    "def transcribe_gcs_with_word_time_offsets(event_metadata,INPUT_BUCKET,filename,punctuation):\n",
    "  \"\"\"\n",
    "  1. load audio file from trigger bucket\n",
    "  2. Getting audio file in right format - set 1 channel; retrieve framerate for API\n",
    "  3. Return Speech-to-text object \n",
    "  \"\"\"\n",
    "\n",
    "  #assemble global file uri\n",
    "  gcs_uri = 'gs://' + INPUT_BUCKET + '/' + filename\n",
    "  #load bucket audio file to tmp folder\n",
    "  tmp_path_name = get_file_path(filename)\n",
    "  bucket = client.get_bucket(event_metadata['bucket'])\n",
    "  blob = bucket.get_blob(event_metadata['name'])\n",
    "  blob.download_to_filename(tmp_path_name)\n",
    "  print(\"filesize before convertion:\",os.path.getsize(tmp_path_name))\n",
    "  if (os.path.getsize(tmp_path_name)>10000000):\n",
    "    print(\"filesize to big->abort\")\n",
    "    os.remove(tmp_path_name)\n",
    "    sys.exit(0)\n",
    "  client_speech = speech.SpeechClient()\n",
    "\n",
    "  # if .wav format, transform to .mp3\n",
    "  if filename.lower().endswith('.wav'):\n",
    "    sound = AudioSegment.from_wav(tmp_path_name)\n",
    "    sound = sound.set_channels(1)\n",
    "    os.remove(tmp_path_name)\n",
    "    tmp_path_name=tmp_path_name+\".mp3\"\n",
    "    filename=filename+\".mp3\"\n",
    "    sound.export(tmp_path_name, format=\"mp3\")\n",
    "    print(\"filesize after convertion:\",os.path.getsize(tmp_path_name))\n",
    "    if (os.path.getsize(tmp_path_name)>10000000):\n",
    "        print(\"filesize to big after conversion->abort\")\n",
    "        os.remove(tmp_path_name)\n",
    "        sys.exit(0)\n",
    "    \n",
    "  sound = AudioSegment.from_mp3(tmp_path_name)\n",
    "  frame_rate=sound.frame_rate\n",
    "  channels=sound.channels\n",
    "  sound = sound.set_channels(1)\n",
    "  #upload to storage for URI access on audio file by google cloud speech api   \n",
    "  name_test=\"post\"+filename\n",
    "  bucket_tmp_path = get_file_path(name_test)\n",
    "  sound.export(bucket_tmp_path, format=\"mp3\")\n",
    "  bucket = client.get_bucket(OUTPUT_BUCKET)\n",
    "  newblob = bucket.blob(name_test)    \n",
    "  newblob.upload_from_filename(bucket_tmp_path)\n",
    "  gcs_uri = 'gs://' + OUTPUT_BUCKET + '/' + \"post\"+filename\n",
    "  audio = speech.types.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "  #general configuration of api NOTE! HERE YOU CAN CHANGE THE LANGUAGE_CODE, MODEL AND OTHER SETTINGS\n",
    "  config = speech.types.RecognitionConfig(\n",
    "        encoding=speech.enums.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        audio_channel_count=channels,\n",
    "        language_code='en-US',\n",
    "        model='default',\n",
    "        enable_word_time_offsets=True,\n",
    "        enable_automatic_punctuation=punctuation)\n",
    "  #send config and audio to the API to retrieve the text\n",
    "  operation = client_speech.long_running_recognize(config, audio)\n",
    "\n",
    "  #delete local tmp file we used earlier (only deletes the cloud function tmp file) \n",
    "  os.remove(tmp_path_name)\n",
    "  print('2. Waiting for transcription to complete. For File:', filename)\n",
    "  result = operation.result(timeout=400)\n",
    "  return result, filename\n",
    "  \n",
    "def process_to_file(result,filename):  \n",
    "    \"\"\"\n",
    "    1. initiates an output file of a srt format\n",
    "    2. generated text file will be parsed word by word and a sentence is generated\n",
    "    3. A sentence represents a caption time-frame and follows two closing conditions\n",
    "      a) Not longer than 4 seconds (SUB_FRAME variable to tune it)\n",
    "      b) If last retrieved word, sentence finished (end_flag controls it)\n",
    "      c) Amount of words: Not implemented in this version but you simple count the len(sentence) and set a closing condition on a var e.g. MAX_LEN\n",
    "    \"\"\"  \n",
    "    #set output file tmp path\n",
    "    path_name_output = get_file_path(filename+\"output.txt\")\n",
    "    SUB_FRAME=4 #length of sentence in seconds\n",
    "    \n",
    "    #open local tmp file and leave it open. The print commands will insert the lines in the tmp file f.\n",
    "    f = open(path_name_output, \"a\")\n",
    "    timer=0.0       # Timer to set current sentence time reference point \n",
    "    caption_index=1 # Current sentence caption number\n",
    "    for result in result.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        \n",
    "        # Transcript and confidence show the whole text + the confidence of the ML recognition\n",
    "        #print('Transcript: {}'.format(alternative.transcript), file=f)\n",
    "        #print('Confidence: {}'.format(alternative.confidence), file=f)\n",
    "        sentence=\"\"     # Initial sentence \n",
    "        itera=0         # Current word loop index\n",
    "\n",
    "        end_flag=False  # Flag gets set True when last word will be looped over\n",
    "        \n",
    "        for word_info in alternative.words:\n",
    "            print(\"word_info.word\",word_info.word)\n",
    "            itera+=1\n",
    "\n",
    "            #if last word, set end_flag True\n",
    "            if(itera>=len(alternative.words)):\n",
    "              end_flag=True\n",
    "            \n",
    "            #get word start- and end-time; end_time_p contains transformation in seconds\n",
    "            word = word_info.word\n",
    "            start_time = word_info.start_time\n",
    "            end_time = word_info.end_time\n",
    "            end_time_p=end_time.seconds + end_time.nanos * 1e-9\n",
    "            print(\"first check timer:\", timer,\"<=\",\" end-time:\",end_time_p ,\"sub_frame:\",SUB_FRAME)\n",
    "            if(timer-end_time_p<=-SUB_FRAME and end_flag==False):\n",
    "              print(caption_index, file=f)\n",
    "              date_start = datetime.datetime.fromtimestamp(timer).strftime('%H:%M:%S,%f')[:-3]\n",
    "              date_end = datetime.datetime.fromtimestamp(end_time_p).strftime('%H:%M:%S,%f')[:-3]\n",
    "              print(date_start,\"-->\",date_end, file=f)\n",
    "              print(sentence, file=f)\n",
    "              print(\"\", file=f)\n",
    "              timer=end_time_p\n",
    "            \n",
    "              #init new sentence with current word\n",
    "              sentence=word+\" \"\n",
    "              caption_index+=1\n",
    "                \n",
    "            #else if last loop->create last caption output\n",
    "            elif(end_flag==True):\n",
    "              sentence=sentence+word+\" \"\n",
    "              date_start = datetime.datetime.fromtimestamp(timer).strftime('%H:%M:%S,%f')[:-3]\n",
    "              date_end = datetime.datetime.fromtimestamp(end_time_p).strftime('%H:%M:%S,%f')[:-3]\n",
    "              print(caption_index , file=f)\n",
    "              print(date_start,\"-->\",date_end , file=f)\n",
    "              print(sentence, file=f)\n",
    "              print(\"\", file=f)\n",
    "              timer=end_time_p\n",
    "              sentence=\"\"\n",
    "              caption_index+=1\n",
    "                \n",
    "            #else, just add the word to the sentence and take next word\n",
    "            else:\n",
    "              sentence=sentence+word+\" \"\n",
    "\n",
    "    #close and save file to tmp folder\n",
    "    f.close()\n",
    "    return path_name_output\n",
    "\n",
    "def process_to_file_translate(result,filename):\n",
    "    #set output file tmp path\n",
    "    print('Waiting for translation to complete. For File:', filename)\n",
    "    target_language=TARGET_LANGUAGE\n",
    "    path_name_output_translate = get_file_path(filename+\"output_translated.txt\")\n",
    "    #SUB_FRAME=4 #length of sentence in seconds\n",
    "    result=result\n",
    "    timer=0.0\n",
    "    caption_index=1\n",
    "    f = open(path_name_output_translate, \"a\")\n",
    "    for result in result.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        #print('Transcript: {}'.format(alternative.transcript))\n",
    "        #print('Confidence: {}'.format(alternative.confidence))\n",
    "        sentence=\"\"\n",
    "        itera=0\n",
    "        end_flag=False\n",
    "        for word_info in alternative.words:\n",
    "            itera+=1\n",
    "            word = word_info.word\n",
    "            end_time_p=word_info.end_time.seconds + word_info.end_time.nanos * 1e-9\n",
    "            sentence=sentence+word+\" \"\n",
    "            if(word.endswith(('.', '?'))):\n",
    "              translated_sentence=translate_text(sentence, target_language)\n",
    "              print(caption_index, file=f)\n",
    "              date_start = datetime.datetime.fromtimestamp(timer).strftime('%H:%M:%S,%f')[:-3]\n",
    "              date_end = datetime.datetime.fromtimestamp(end_time_p).strftime('%H:%M:%S,%f')[:-3]\n",
    "              print(date_start,\"-->\",date_end, file=f)\n",
    "              print(translated_sentence, file=f)\n",
    "              print(sentence, file=f)\n",
    "              print(\"\", file=f)\n",
    "              timer=end_time_p\n",
    "              sentence=\"\"\n",
    "              caption_index+=1\n",
    "\n",
    "    f.close()\n",
    "    return path_name_output_translate  \n",
    "  \n",
    "def make_subtitles(event_metadata, context):\n",
    "    INPUT_BUCKET = event_metadata['bucket']\n",
    "    FILENAME = event_metadata['name']\n",
    "    FILE_URI = event_metadata['name']\n",
    "    # Speech-To-Text function\n",
    "    print('1. retrieved data:',FILENAME)\n",
    "    punctuation=True # set False for transcription without translation. Less computing\n",
    "    result_fetch_translate, FILENAME=transcribe_gcs_with_word_time_offsets(event_metadata,INPUT_BUCKET,FILENAME, punctuation)\n",
    "    print('transcription complete for:',FILENAME) \n",
    "    result_fetch=result_fetch_translate\n",
    "    # Manipuating retrieved path of Text-to-.srt file \n",
    "    foutput_file_name=process_to_file(result_fetch,FILENAME)\n",
    "\n",
    "    # Upload the .srt file in output bucket\n",
    "    bucket = client.get_bucket(OUTPUT_BUCKET)\n",
    "    newblob = bucket.blob(FILENAME+\".txt\")  \n",
    "    newblob.upload_from_filename(foutput_file_name)\n",
    "    if FLAG_TRANSLATE:\n",
    "        print('3. init translation for:',FILENAME) \n",
    "        foutput_file_name_translate=process_to_file_translate(result_fetch_translate,FILENAME)\n",
    "        print('translation complete for:',FILENAME) \n",
    "        newblob2 = bucket.blob(FILENAME+\"translated.txt\")  \n",
    "        newblob2.upload_from_filename(foutput_file_name_translate)\n",
    "        #remove local stored files\n",
    "        os.remove(foutput_file_name_translate)\n",
    "        \n",
    "    #remove local stored files\n",
    "    os.remove(foutput_file_name)\n",
    "\n",
    "\n",
    "def translate_text(text, target_language_p):\n",
    "    translate_client = translate.Client()\n",
    "    result = translate_client.translate(\n",
    "        text, target_language=target_language_p)\n",
    "\n",
    "    #print(u'Text: {}'.format(result['input']))\n",
    "    #print(u'Translation: {}'.format(result['translatedText']))\n",
    "    #print(u'Detected source language: {}'.format(result['detectedSourceLanguage']))\n",
    "    return result['translatedText']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpKPRz4MN0Ee"
   },
   "source": [
    "## Deploy cloud function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kaa62e7ZNqQC"
   },
   "source": [
    " The following command should show you the mian.py and requirements.txt file. For the deployment we need the main.py and requirements.txt in the same current working folder or you will get module import errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwZ8WrJLMhwI"
   },
   "source": [
    "Now we have the two required files. Next we deploy the cloud function via bash command.\n",
    "\n",
    "\"make_subtitles\"= name of main exectuion function\n",
    "\n",
    "\"trigger-resource\"= id of trigger_bucket to listen for incoming new audio files\n",
    "\n",
    "\"google.storage.object.finalize\"= one of 4 options to trigger the cloud function. In this case on the creation of new files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPAvl1IQlVOd",
    "outputId": "8d85bd18-b51d-4b26-ed7b-4c1bcf8749fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "availableMemoryMb: 256\n",
      "entryPoint: make_subtitles\n",
      "eventTrigger:\n",
      "  eventType: google.storage.object.finalize\n",
      "  failurePolicy: {}\n",
      "  resource: projects/_/buckets/trigger-caaef4f5-eccf-4405-bd3d-595622299e5f\n",
      "  service: storage.googleapis.com\n",
      "ingressSettings: ALLOW_ALL\n",
      "labels:\n",
      "  deployment-tool: cli-gcloud\n",
      "name: projects/cloudfunction-268018/locations/us-central1/functions/make_subtitles\n",
      "runtime: python37\n",
      "serviceAccountEmail: cloudfunction-268018@appspot.gserviceaccount.com\n",
      "sourceUploadUrl: https://storage.googleapis.com/gcf-upload-us-central1-af29b935-e25b-48ea-9946-84d6982eec89/c4d1e942-b9c3-4466-a982-6e134f8052b0.zip?GoogleAccessId=service-410169410576@gcf-admin-robot.iam.gserviceaccount.com&Expires=1581595370&Signature=FA3ullB1Yh1e2tP9DQvd93nO7x0gtK9E%2FDDIW1jVZriXxQfY0misMBMPnQcQ8NQXwpsXD6GGmCHaXFr7wz3bMzuD9jZBIYDaqi02c3np%2BbyGi54AB%2FwM1ZHZbKkaMkCdDvA5WQWcb7Wby5pVwL%2BClFxwS%2B2rRy69RLPmphL7NHdBf9VSsk0FGKbGe4KDLy2%2BQcNYKyHI%2FZRfiPJU%2FRaRIQ6K74auT7qnhSqB99jvgRK5JlusYCcShZAFv7IeufLjIXL%2ByEwY3StpbitrZlecCmbLg2Mp2ppndw3Pao8qyB0tix7XaBj0KLWxnwvNxx5QuV3NBqu90MF6sZ8pIJyV8A%3D%3D\n",
      "status: ACTIVE\n",
      "timeout: 200s\n",
      "updateTime: '2020-02-13T11:34:16Z'\n",
      "versionId: '1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allow unauthenticated invocations of new function [make_subtitles]? \n",
      "(y/N)?  \n",
      "WARNING: Function created with limited-access IAM policy. To enable unauthorized access consider \"gcloud alpha functions add-iam-policy-binding make_subtitles --region=us-central1 --member=allUsers --role=roles/cloudfunctions.invoker\"\n",
      "Deploying function (may take a while - up to 2 minutes)...\n",
      "...........................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TARGET_STORAGE=gs://${trigger_Bucket}\n",
    "gcloud functions deploy make_subtitles --region ${REGION} --runtime python37 --timeout 200s --trigger-resource $TARGET_STORAGE --trigger-event google.storage.object.finalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WS0HJM1mUTAx"
   },
   "source": [
    "after the function is deployed(aprox. 2min), you can upload a file to the target folder. Upload your file and afterwards set the correct name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_name2=\"output2-1channel.mp3\"\n",
    "os.environ['File_name2'] = File_name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://trigger-caaef4f5-eccf-4405-bd3d-595622299e5f/output2-1channel.mp3...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "Copying file://output2-1channel.mp3 [Content-Type=audio/mpeg]...\n",
      "/ [1 files][  1.3 MiB/  1.3 MiB]                                                \n",
      "Operation completed over 1 objects/1.3 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "LOCAL_FILE=${File_name2}\n",
    "INPUT=gs://${trigger_Bucket}\n",
    "gsutil rm $INPUT/$LOCAL_FILE\n",
    "gsutil cp $LOCAL_FILE $INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r results\n",
    "!mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2-1channel.wav.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2-1channellow.wav.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2-1channel.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2-2channel.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2-2channel.wav.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2-std-1c-24k.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2.mp3.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/output2.mp3translated.txt...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2-1channellow.wav.mp3...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2-1channel.mp3...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2.mp3...     \n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2-1channel.wav.mp3...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2-std-1c-24k.mp3...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2-2channel.wav.mp3...\n",
      "Copying gs://output-39f8058a-242b-44ff-b2b3-b86aa36643fc/postoutput2-2channel.mp3...\n",
      "/ [15/15 files][  7.5 MiB/  7.5 MiB] 100% Done                                  \n",
      "Operation completed over 15 objects/7.5 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTPUT_BUCKET=${Output_Bucket}\n",
    "gsutil -m cp -R gs://$OUTPUT_BUCKET results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vf6fbefzMUsR"
   },
   "source": [
    "## [ALTERNATIVE] Following code creates a zipfile, which can be used for the manual deployment in google cloud functions via the google cloud console web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "dMbHMgGmiu7I",
    "outputId": "3732250c-5bc9-4635-bc13-65e1bcd25a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting zipfile36\n",
      "  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: zipfile36\n",
      "Successfully installed zipfile36-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install zipfile36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mkgj9Ixiypq"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('cloud_function.zip', 'w') as zipObj:\n",
    "   # Add multiple files to the zip\n",
    "   zipObj.write('main.py')\n",
    "   zipObj.write('requirements.txt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "speech_transcription_v2_(1)_(2)_(1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
